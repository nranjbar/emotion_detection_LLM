{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"80c2cd9407004e6fb7ad25bcddd2f963":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d76a9c78c3f45e9a023f224c3d6cb03","IPY_MODEL_6deb6ec92ecc400fb8518879fb7da7d0","IPY_MODEL_7d034e0b529f451e95f773532bda688a"],"layout":"IPY_MODEL_4611110c6f2b42008d1451c91e51e5ce"}},"7d76a9c78c3f45e9a023f224c3d6cb03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_715bbd30d4d74f389ebb0f9febd6ab00","placeholder":"​","style":"IPY_MODEL_c14f0f0220314870baee14d6faeb087d","value":"model.safetensors: 100%"}},"6deb6ec92ecc400fb8518879fb7da7d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_716c87348b814014bff7e648c4b6ed4b","max":4138270819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5d3be3c20d64f3fa4a9a9198b571a72","value":4138270425}},"7d034e0b529f451e95f773532bda688a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6ef57e1ef884d9db2d777d1a7cc1637","placeholder":"​","style":"IPY_MODEL_cb33541e671a4bae94278591d7698faf","value":" 4.14G/4.14G [00:26&lt;00:00, 282MB/s]"}},"4611110c6f2b42008d1451c91e51e5ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"715bbd30d4d74f389ebb0f9febd6ab00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c14f0f0220314870baee14d6faeb087d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"716c87348b814014bff7e648c4b6ed4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d3be3c20d64f3fa4a9a9198b571a72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6ef57e1ef884d9db2d777d1a7cc1637":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb33541e671a4bae94278591d7698faf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31d51b67512749ec8e2633ceeea2802a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7299d8369dd7401d863f00858b5a5175","IPY_MODEL_4f5a25befb09499da5d7ad6561380443","IPY_MODEL_91276e5527dd43ddbc5f27b4904b83e2"],"layout":"IPY_MODEL_0bda1889d75848a2b2f00c2575c7d2ad"}},"7299d8369dd7401d863f00858b5a5175":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e859cc6c04184951a60fca2595cf1a4b","placeholder":"​","style":"IPY_MODEL_3b534eecdfc8424a9cd10b178c471eb4","value":"generation_config.json: 100%"}},"4f5a25befb09499da5d7ad6561380443":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c24d64e8a884822946b7fb262d3e481","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d791f92d8fd4a0abffce850a40a4d0a","value":157}},"91276e5527dd43ddbc5f27b4904b83e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29a3990bfa7845a7a6f04c1692fcdf8a","placeholder":"​","style":"IPY_MODEL_5ae0352f5ec84566983124a00154a247","value":" 157/157 [00:00&lt;00:00, 4.76kB/s]"}},"0bda1889d75848a2b2f00c2575c7d2ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e859cc6c04184951a60fca2595cf1a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b534eecdfc8424a9cd10b178c471eb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c24d64e8a884822946b7fb262d3e481":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d791f92d8fd4a0abffce850a40a4d0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29a3990bfa7845a7a6f04c1692fcdf8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ae0352f5ec84566983124a00154a247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b286ec5610fe4020a9a738d0287fdc82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f5f99ee383f4064b2e492f15677e753","IPY_MODEL_8f3655b9e8dc40ffb03b76afebf2523b","IPY_MODEL_8113936197a94064acba7784882527ee"],"layout":"IPY_MODEL_a3a7306e87b544508020df43894c6c58"}},"0f5f99ee383f4064b2e492f15677e753":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f106dd3171ee4eef849f3742d34caab8","placeholder":"​","style":"IPY_MODEL_b5c61e446a934af08f64b4a0e643453c","value":"tokenizer_config.json: 100%"}},"8f3655b9e8dc40ffb03b76afebf2523b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a9106b26bf3434699b16d3772021944","max":140911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48168b1e00de49d3ad253a1ede94f87f","value":140911}},"8113936197a94064acba7784882527ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6724062ffe984b75a66821551b2763bf","placeholder":"​","style":"IPY_MODEL_a9dd0a311f4740ab9e9e04f0ec976f7d","value":" 141k/141k [00:00&lt;00:00, 806kB/s]"}},"a3a7306e87b544508020df43894c6c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f106dd3171ee4eef849f3742d34caab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c61e446a934af08f64b4a0e643453c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a9106b26bf3434699b16d3772021944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48168b1e00de49d3ad253a1ede94f87f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6724062ffe984b75a66821551b2763bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9dd0a311f4740ab9e9e04f0ec976f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a0a59d50de3462eaad87c845ab6a1e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46f3e84a33b94cdcb855fbf0a47a345d","IPY_MODEL_2d1c2c65324e4eefa2e4f2ffe93d60c8","IPY_MODEL_368fa6a7caa642ff9461e389e3030a91"],"layout":"IPY_MODEL_ef320625a15e4e9e86b4784c90974a32"}},"46f3e84a33b94cdcb855fbf0a47a345d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f715778fcdc4b1f93004b0a4fe99451","placeholder":"​","style":"IPY_MODEL_5c86e759aa334b37812187890522c3fb","value":"tokenizer.model: 100%"}},"2d1c2c65324e4eefa2e4f2ffe93d60c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_307c3dd5a1f346aba00c082d37bbf795","max":587404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2fc5ee1ee094c269e79763288b456f7","value":587404}},"368fa6a7caa642ff9461e389e3030a91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3a80d3748484f73ba9666706d448004","placeholder":"​","style":"IPY_MODEL_eeb4d0e98eca43e180b4b1908fde7fe8","value":" 587k/587k [00:00&lt;00:00, 7.03MB/s]"}},"ef320625a15e4e9e86b4784c90974a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f715778fcdc4b1f93004b0a4fe99451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c86e759aa334b37812187890522c3fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"307c3dd5a1f346aba00c082d37bbf795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2fc5ee1ee094c269e79763288b456f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3a80d3748484f73ba9666706d448004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeb4d0e98eca43e180b4b1908fde7fe8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fd57f62db234ea7a3a9cba251a322f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26ac55c65e0f47338f55504e9dfc3b01","IPY_MODEL_59a718ad3bc540878cf56b347b2fe071","IPY_MODEL_1f4a58af4c3643348f84c43fe301637c"],"layout":"IPY_MODEL_714f657c4ff342c081e342af8cc5db6d"}},"26ac55c65e0f47338f55504e9dfc3b01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c60a53c3e644d30a9cc672374d5487a","placeholder":"​","style":"IPY_MODEL_c7e1aa602a924d609fd23f7c28a2879f","value":"special_tokens_map.json: 100%"}},"59a718ad3bc540878cf56b347b2fe071":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_558bb66ec3d649819f633ff5cb23571f","max":446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b22c0eb97834099a4cfd853d86d8a5f","value":446}},"1f4a58af4c3643348f84c43fe301637c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ed13eaebd9f4b179ed5db29489aad51","placeholder":"​","style":"IPY_MODEL_2faf7e3455344666a266cbaacd185405","value":" 446/446 [00:00&lt;00:00, 13.2kB/s]"}},"714f657c4ff342c081e342af8cc5db6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c60a53c3e644d30a9cc672374d5487a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7e1aa602a924d609fd23f7c28a2879f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"558bb66ec3d649819f633ff5cb23571f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b22c0eb97834099a4cfd853d86d8a5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ed13eaebd9f4b179ed5db29489aad51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2faf7e3455344666a266cbaacd185405":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccd18cb46eba489ba38ffbe5db796423":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f706ad9c57da4c50a60ce613f21ec306","IPY_MODEL_624af38b9c5b43dc80e193ba3f129195","IPY_MODEL_90c84d6a06b04db19a3e35f27a1af373"],"layout":"IPY_MODEL_1b573db1392544e78fcdf6967784aae6"}},"f706ad9c57da4c50a60ce613f21ec306":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba98f9afc0f4732ae6e887db19392f3","placeholder":"​","style":"IPY_MODEL_5017db9e3c1d4222bf97f2b1573a25b1","value":"tokenizer.json: 100%"}},"624af38b9c5b43dc80e193ba3f129195":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbf12eb1746486d80ae9746cb4d2fd2","max":1961548,"min":0,"orientation":"horizontal","style":"IPY_MODEL_901e429fb9c24a9c915f586bbefee0ab","value":1961548}},"90c84d6a06b04db19a3e35f27a1af373":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bce62435458a423792b5e91f182242c4","placeholder":"​","style":"IPY_MODEL_ed12ea816d474f5ca76237adaeef3290","value":" 1.96M/1.96M [00:00&lt;00:00, 2.81MB/s]"}},"1b573db1392544e78fcdf6967784aae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba98f9afc0f4732ae6e887db19392f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5017db9e3c1d4222bf97f2b1573a25b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cbf12eb1746486d80ae9746cb4d2fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901e429fb9c24a9c915f586bbefee0ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bce62435458a423792b5e91f182242c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed12ea816d474f5ca76237adaeef3290":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9759076a402a48ed84cefe8054b6c302":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_106e1a4c42f84d09a8bc52e4fb857c7b","IPY_MODEL_2639f5bac87f4b82ab5de48c0c81ef27","IPY_MODEL_a4f06c8be9b34586a499a22b4075fd99"],"layout":"IPY_MODEL_8ab27d1c33c74db2b80d5dc98c808f0a"}},"106e1a4c42f84d09a8bc52e4fb857c7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8a1a8bb12f74a7e8fc289ed4af8a33c","placeholder":"​","style":"IPY_MODEL_1ba372328f2047c9b6ce07bd6997854a","value":"Map (num_proc=2): 100%"}},"2639f5bac87f4b82ab5de48c0c81ef27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e4acb35cc443929ee0ec7eab53574c","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d3e3394f17a41ccba551e30388822ee","value":150}},"a4f06c8be9b34586a499a22b4075fd99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f05c914b55d4679aba82f9d06dcfb6e","placeholder":"​","style":"IPY_MODEL_14a580993f7745198f6de98f73610afc","value":" 150/150 [00:01&lt;00:00, 77.94 examples/s]"}},"8ab27d1c33c74db2b80d5dc98c808f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8a1a8bb12f74a7e8fc289ed4af8a33c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba372328f2047c9b6ce07bd6997854a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93e4acb35cc443929ee0ec7eab53574c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d3e3394f17a41ccba551e30388822ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f05c914b55d4679aba82f9d06dcfb6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14a580993f7745198f6de98f73610afc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10848613,"sourceType":"datasetVersion","datasetId":6416969}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/emotion-dataset/df_train_with_explanation.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:16.945039Z","iopub.execute_input":"2025-02-25T16:14:16.945409Z","iopub.status.idle":"2025-02-25T16:14:16.961952Z","shell.execute_reply.started":"2025-02-25T16:14:16.945380Z","shell.execute_reply":"2025-02-25T16:14:16.961144Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:16.963152Z","iopub.execute_input":"2025-02-25T16:14:16.963443Z","iopub.status.idle":"2025-02-25T16:14:16.966609Z","shell.execute_reply.started":"2025-02-25T16:14:16.963407Z","shell.execute_reply":"2025-02-25T16:14:16.965917Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n    \"unsloth/Phi-3-medium-4k-instruct\",\n    \"unsloth/gemma-2-9b-bnb-4bit\",\n    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n    \n    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\", # or choose \"unsloth/Llama-3.2-1B\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:16.967930Z","iopub.execute_input":"2025-02-25T16:14:16.968194Z","iopub.status.idle":"2025-02-25T16:14:45.673563Z","shell.execute_reply.started":"2025-02-25T16:14:16.968170Z","shell.execute_reply":"2025-02-25T16:14:45.672858Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ffce3a211d24b40941d6e82d7746479"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67de61756be14719892c8b4a1b220a57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3012325d5c4844a08a91fb999bd41034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45f076e7afc4acfa0becc4cf6317f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60205edb47c1478e8fc0e1579c3c439d"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af9ae48a-17d1-4d78-d482-6e0cce8538ee","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:45.674636Z","iopub.execute_input":"2025-02-25T16:14:45.674912Z","iopub.status.idle":"2025-02-25T16:14:52.011479Z","shell.execute_reply.started":"2025-02-25T16:14:45.674876Z","shell.execute_reply":"2025-02-25T16:14:52.010560Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"N4xIpZT-AkE6","outputId":"dc535da5-a743-493d-b7df-c43494778d2b","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:52.032663Z","iopub.execute_input":"2025-02-25T16:14:52.032924Z","iopub.status.idle":"2025-02-25T16:14:52.051145Z","shell.execute_reply.started":"2025-02-25T16:14:52.032904Z","shell.execute_reply":"2025-02-25T16:14:52.050465Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                       id  \\\n0              0  eng_train_track_a_00001   \n1              1  eng_train_track_a_00002   \n2              2  eng_train_track_a_00003   \n3              3  eng_train_track_a_00004   \n4              4  eng_train_track_a_00005   \n...          ...                      ...   \n2763        2763  eng_train_track_a_02764   \n2764        2764  eng_train_track_a_02765   \n2765        2765  eng_train_track_a_02766   \n2766        2766  eng_train_track_a_02767   \n2767        2767  eng_train_track_a_02768   \n\n                                                   text  Anger  Fear  Joy  \\\n0                                   But not very happy.      0     0    1   \n1     Well she's not gon na last the whole song like...      0     0    1   \n2     She sat at her Papa's recliner sofa only to mo...      0     0    0   \n3                       Yes, the Oklahoma city bombing.      1     1    0   \n4                          They were dancing to Bolero.      0     0    1   \n...                                                 ...    ...   ...  ...   \n2763                 \"Yeah, but did you just find that?      0     1    0   \n2764  I did as little as possible with my right hand...      0     0    0   \n2765                            Okay that sucks, right?      1     0    0   \n2766  The spark leaped through his body into mine, a...      0     1    0   \n2767  He had 4 inches and 40 pounds on me and I stil...      0     0    1   \n\n      Sadness  Surprise                              generated_explanation  \n0           1         0  The speaker conveys a sense of dissatisfaction...  \n1           0         0  The speaker describes a moment of physical sup...  \n2           0         0  The speaker describes a moment of comfort or c...  \n3           1         1  The speaker references a significant historica...  \n4           0         0  The mention of a specific song evokes a sense ...  \n...       ...       ...                                                ...  \n2763        0         1  The speaker expresses surprise or curiosity, p...  \n2764        0         0  The speaker describes self-care after an injur...  \n2765        1         0  The speaker acknowledges a negative situation,...  \n2766        0         1  The speaker describes a sudden, intense connec...  \n2767        0         1  The speaker describes a victory, emphasizing p...  \n\n[2768 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>text</th>\n      <th>Anger</th>\n      <th>Fear</th>\n      <th>Joy</th>\n      <th>Sadness</th>\n      <th>Surprise</th>\n      <th>generated_explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>eng_train_track_a_00001</td>\n      <td>But not very happy.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker conveys a sense of dissatisfaction...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>eng_train_track_a_00002</td>\n      <td>Well she's not gon na last the whole song like...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes a moment of physical sup...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>eng_train_track_a_00003</td>\n      <td>She sat at her Papa's recliner sofa only to mo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes a moment of comfort or c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>eng_train_track_a_00004</td>\n      <td>Yes, the Oklahoma city bombing.</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>The speaker references a significant historica...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>eng_train_track_a_00005</td>\n      <td>They were dancing to Bolero.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The mention of a specific song evokes a sense ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2763</th>\n      <td>2763</td>\n      <td>eng_train_track_a_02764</td>\n      <td>\"Yeah, but did you just find that?</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>The speaker expresses surprise or curiosity, p...</td>\n    </tr>\n    <tr>\n      <th>2764</th>\n      <td>2764</td>\n      <td>eng_train_track_a_02765</td>\n      <td>I did as little as possible with my right hand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes self-care after an injur...</td>\n    </tr>\n    <tr>\n      <th>2765</th>\n      <td>2765</td>\n      <td>eng_train_track_a_02766</td>\n      <td>Okay that sucks, right?</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker acknowledges a negative situation,...</td>\n    </tr>\n    <tr>\n      <th>2766</th>\n      <td>2766</td>\n      <td>eng_train_track_a_02767</td>\n      <td>The spark leaped through his body into mine, a...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>The speaker describes a sudden, intense connec...</td>\n    </tr>\n    <tr>\n      <th>2767</th>\n      <td>2767</td>\n      <td>eng_train_track_a_02768</td>\n      <td>He had 4 inches and 40 pounds on me and I stil...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>The speaker describes a victory, emphasizing p...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2768 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nimport json\n\n# Example DataFrame assuming it contains the necessary columns\n# df: text, generated_explanation, Anger, Fear, Joy, Sadness, Surprise\n\n# Define the instruction for generating emotional responses\ninstruction = (\n    \"Read the provided text carefully and predict the emotional response based on the context. For each of the following emotions — anger, fear, joy, sadness, and surprise — determine whether it is present in the text. \"\n    \"of the sentence. The response should be in a JSON format with emotions as keys and binary values (1 for present, 0 for absent). Please ensure that your response accurately reflects the context and emotional tone conveyed by the sentence.\"\n)\n\n# Function to convert the emotion labels to a JSON format\ndef format_emotions(row):\n    # Create a dictionary with emotions as keys and binary values\n    emotions = {\n        \"Anger\": 1 if row['Anger'] == 1 else 0,\n        \"Fear\": 1 if row['Fear'] == 1 else 0,\n        \"Joy\": 1 if row['Joy'] == 1 else 0,\n        \"Sadness\": 1 if row['Sadness'] == 1 else 0,\n        \"Surprise\": 1 if row['Surprise'] == 1 else 0\n    }\n    \n    # Return the JSON formatted string\n    return json.dumps(emotions)\n\n# Apply the function to create emotion labels\ndf['formatted_emotion'] = df.apply(format_emotions, axis=1)\n\n# Prepare the dataset for fine-tuning with the appropriate prompt format\nalpaca_prompt = \"\"\"\n### Instruction:\n{}\n### Input:\n{}\n### Response:\n{}\"\"\"\n\nEOS_TOKEN = \"<|endoftext|>\"  # Replace with the tokenizer's EOS token if necessary\n\n# Create the prompts\ndf[\"formatted_prompt\"] = df.apply(\n    lambda row: alpaca_prompt.format(\n        instruction, row[\"text\"],  row[\"formatted_emotion\"]\n    ) + EOS_TOKEN, axis=1\n)\n\n# Convert to Hugging Face dataset\ndataset = Dataset.from_pandas(df[[\"formatted_prompt\"]])\n\n# The dataset is now ready for fine-tuning\n","metadata":{"id":"a8Xy9LO4ZVJE","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:52.052026Z","iopub.execute_input":"2025-02-25T16:14:52.052301Z","iopub.status.idle":"2025-02-25T16:14:52.149514Z","shell.execute_reply.started":"2025-02-25T16:14:52.052280Z","shell.execute_reply":"2025-02-25T16:14:52.148879Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"dataset['formatted_prompt']","metadata":{"id":"7Mts_hqvZi_n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70d75cb9-4d86-4ea8-abf1-b6f9ce8b4891","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"Train\"></a>\n### Train the model\nNow let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!","metadata":{"id":"idAEIeSQ3xdS"}},{"cell_type":"code","source":"!export WANDB_MODE=disabled","metadata":{"id":"_GuzsTd_bMQT","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:52.184063Z","iopub.execute_input":"2025-02-25T16:14:52.184402Z","iopub.status.idle":"2025-02-25T16:14:52.378636Z","shell.execute_reply.started":"2025-02-25T16:14:52.184372Z","shell.execute_reply":"2025-02-25T16:14:52.377645Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"formatted_prompt\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 30,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to='none',\n    ),\n)\n","metadata":{"id":"95_Nn-89DhsL","colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["9759076a402a48ed84cefe8054b6c302","106e1a4c42f84d09a8bc52e4fb857c7b","2639f5bac87f4b82ab5de48c0c81ef27","a4f06c8be9b34586a499a22b4075fd99","8ab27d1c33c74db2b80d5dc98c808f0a","a8a1a8bb12f74a7e8fc289ed4af8a33c","1ba372328f2047c9b6ce07bd6997854a","93e4acb35cc443929ee0ec7eab53574c","2d3e3394f17a41ccba551e30388822ee","7f05c914b55d4679aba82f9d06dcfb6e","14a580993f7745198f6de98f73610afc"]},"outputId":"b5c77a7f-d483-4ac4-c665-995ce250b206","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:52.380305Z","iopub.execute_input":"2025-02-25T16:14:52.380562Z","iopub.status.idle":"2025-02-25T16:14:58.529235Z","shell.execute_reply.started":"2025-02-25T16:14:52.380540Z","shell.execute_reply":"2025-02-25T16:14:58.528486Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML (num_proc=2):   0%|          | 0/2768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e8b6a8c3a14cd295f6cbdefc77afe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/2768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d51f345dc24f7cbd2a66b57922461a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/2768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dffd6e668fe94ad2b3d17eae30f1e1a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/2768 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286b8b1cb6c1440f9f4c56ea27c934cb"}},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"18278ca3-bd6b-46a0-dabd-b110b4f7750c","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:58.530358Z","iopub.execute_input":"2025-02-25T16:14:58.530687Z","iopub.status.idle":"2025-02-25T16:14:58.536372Z","shell.execute_reply.started":"2025-02-25T16:14:58.530653Z","shell.execute_reply":"2025-02-25T16:14:58.535721Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n12.455 GB of memory reserved.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"id":"yqxqAZ7KJ4oL","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"52efa6af-d0e6-44a2-dd03-abe74c40fd44","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:14:58.537114Z","iopub.execute_input":"2025-02-25T16:14:58.537326Z","iopub.status.idle":"2025-02-25T16:18:21.799411Z","shell.execute_reply.started":"2025-02-25T16:14:58.537307Z","shell.execute_reply":"2025-02-25T16:18:21.798552Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 2,768 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 30\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 03:14, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.258200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.243200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.192500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.019400</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.699000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.487500</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.156500</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.910600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.636900</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.551600</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.516300</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.550400</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.384300</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.557400</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.692900</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.527800</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.424700</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.407900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.401700</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.541300</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.508000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.507600</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.427200</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.375200</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.505400</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.368100</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.463000</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.489700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.363400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"id":"pCqnaKmlO1U9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98f78253-86cf-4673-ff2b-923460c2b3fd","cellView":"form","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:18:21.800309Z","iopub.execute_input":"2025-02-25T16:18:21.800586Z","iopub.status.idle":"2025-02-25T16:18:21.807304Z","shell.execute_reply.started":"2025-02-25T16:18:21.800563Z","shell.execute_reply":"2025-02-25T16:18:21.806586Z"}},"outputs":[{"name":"stdout","text":"201.1714 seconds used for training.\n3.35 minutes used for training.\nPeak reserved memory = 13.072 GB.\nPeak reserved memory for training = 0.617 GB.\nPeak reserved memory % of max memory = 88.678 %.\nPeak reserved memory for training % of max memory = 4.186 %.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"<a name=\"Inference\"></a>\n### Inference\nLet's run the model! You can change the instruction and input - leave the output blank!","metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"markdown","source":" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!","metadata":{"id":"CrSvZObor0lY"}},{"cell_type":"code","source":"model.save_pretrained(\"lamma3_model_emotion_detection\") # Local saving\ntokenizer.save_pretrained(\"lamma3_model_emotion_detection\")\n# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving","metadata":{"id":"upcOlWe7A1vc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdd5b069-e944-4c81-8094-468999c210ec","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:18:21.807949Z","iopub.execute_input":"2025-02-25T16:18:21.808179Z","iopub.status.idle":"2025-02-25T16:18:22.871977Z","shell.execute_reply.started":"2025-02-25T16:18:21.808160Z","shell.execute_reply":"2025-02-25T16:18:22.870241Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"('lamma3_model_emotion_detection/tokenizer_config.json',\n 'lamma3_model_emotion_detection/special_tokens_map.json',\n 'lamma3_model_emotion_detection/tokenizer.json')"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# from unsloth import FastLanguageModel\n# import torch\n\n# # Model parameters\n# model_name = \"/kaggle/working/lamma3_model_emotion_detection\"  # Update with your model's name\n# from unsloth import FastLanguageModel\n# model, tokenizer = FastLanguageModel.from_pretrained(\n#         model_name = model_name, # YOUR MODEL YOU USED FOR TRAINING\n#         max_seq_length = max_seq_length,\n#         dtype = dtype,\n#         load_in_4bit = load_in_4bit,\n#     )\n# FastLanguageModel.for_inference(model) # Enable native 2x faster inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:18:22.872774Z","iopub.execute_input":"2025-02-25T16:18:22.873210Z","iopub.status.idle":"2025-02-25T16:18:22.878329Z","shell.execute_reply.started":"2025-02-25T16:18:22.873142Z","shell.execute_reply":"2025-02-25T16:18:22.876908Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"FastLanguageModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:18:22.879942Z","iopub.execute_input":"2025-02-25T16:18:22.880233Z","iopub.status.idle":"2025-02-25T16:18:22.904196Z","shell.execute_reply.started":"2025-02-25T16:18:22.880204Z","shell.execute_reply":"2025-02-25T16:18:22.903185Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport pandas as pd\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\n\n# Define the instruction for generating emotional responses\ninstruction = (\n    \"Read the provided text carefully and predict the emotional response based on the context. For each of the following emotions — anger, fear, joy, sadness, and surprise — determine whether it is present in the text. \"\n    \"of the sentence. The response should be in a JSON format with emotions as keys and binary values (1 for present, 0 for absent). Please ensure that your response accurately reflects the context and emotional tone conveyed by the sentence.\"\n)\n\n# Define the Alpaca-style prompt\nalpaca_prompt = \"\"\"\n### Instruction:\n{}\n### Input:\n{}\n### Response:\n\"\"\"\n\n# Load your test data from a CSV file\ndf_test = pd.read_csv('/kaggle/input/emotion-dataset/df_test_with_explanation.csv')\ndf_test=df_test\n# Custom dataset to handle input prompts\nclass SentenceDataset(Dataset):\n    def __init__(self, dataframe):\n        self.texts = dataframe[\"text\"].tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return alpaca_prompt.format(instruction, self.texts[idx])\n\n\n# Create the dataset and dataloader\nbatch_size = 16\ndataset = SentenceDataset(df_test)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n# Function to generate responses for a batch (predicting emotion labels)\ndef generate_responses_batch(batch):\n    # Tokenize the batch\n    inputs = tokenizer(\n        batch,\n        return_tensors=\"pt\",\n        padding=True,\n        truncation=True,\n        max_length=512,\n    ).to(\"cuda\")\n\n    # Disable gradient computation for faster inference\n    with torch.no_grad():\n        # Generate outputs\n        outputs = model.generate(  # Directly use the model without DataParallel\n            **inputs,\n            max_new_tokens=150,\n            use_cache=True,\n        )\n\n    # Decode the generated outputs\n    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n    # Extract the predicted emotions\n    responses = []\n    for decoded_output in decoded_outputs:\n        response_start = decoded_output.find(\"### Response:\") + len(\"### Response:\")\n        response_end = decoded_output.find(\"<|endoftext|>\")\n        response = decoded_output[response_start:response_end].strip()\n        responses.append(response)\n\n    return responses\n\n# Generate responses and update the DataFrame\ngenerated_responses = []\nfor batch in tqdm(dataloader, desc=\"Generating Responses\"):\n    responses = generate_responses_batch(batch)\n    generated_responses.extend(responses)\n\n# Add generated responses (predicted emotions) to the DataFrame\ndf_test[\"predicted_emotions\"] = generated_responses\n\n# Print the resulting DataFrame with predicted emotions\n# print(df_test[[\"text\", \"predicted_emotions\"]])\n","metadata":{"id":"TGgWTs-YeXsN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"873ea16b-e1a5-435c-db42-157a5d64b979","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.to_csv('Eng_test_predicted_lamma3.csv',index=False)","metadata":{"id":"LvwL2xo6FWLF","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T21:06:48.974782Z","iopub.execute_input":"2025-02-25T21:06:48.975124Z","iopub.status.idle":"2025-02-25T21:06:48.987725Z","shell.execute_reply.started":"2025-02-25T21:06:48.975099Z","shell.execute_reply":"2025-02-25T21:06:48.986708Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\nimport json\nimport numpy as np\n\n# Helper function to parse the JSON format and convert to binary vector\ndef parse_json_emotions(emotion_json):\n    # Convert JSON string to a dictionary\n    emotion_dict = json.loads(emotion_json)\n    # Create a binary vector corresponding to emotions [Anger, Fear, Joy, Sadness, Surprise]\n    emotions_order = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n    return [emotion_dict.get(emotion, 0) for emotion in emotions_order]\n\n# Assuming actual emotion columns in the test data (Anger, Fear, Joy, Sadness, Surprise)\n# Prepare the ground truth (actual emotion columns)\ny_true = df_test[['anger', 'fear', 'joy', 'sadness', 'surprise']].values\n\n# Prepare the predictions: convert predicted_emotions from JSON to binary vector format\ny_pred = []\nfor emotion_json in df_test['predicted_emotions']:\n    pred_vector = parse_json_emotions(emotion_json)\n    y_pred.append(pred_vector)\n\ny_pred = np.array(y_pred)\n\n# Calculate evaluation metrics: Precision, Recall, F1, and Accuracy for each emotion\nprecision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_true, y_pred)\n\n# Print evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nfor i, label in enumerate(['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']):\n    print(f\"Emotion: {label}\")\n    print(f\"  Precision: {precision[i]:.4f}\")\n    print(f\"  Recall: {recall[i]:.4f}\")\n    print(f\"  F1 Score: {f1[i]:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:05:30.007020Z","iopub.execute_input":"2025-02-25T17:05:30.007329Z","iopub.status.idle":"2025-02-25T17:05:30.020576Z","shell.execute_reply.started":"2025-02-25T17:05:30.007306Z","shell.execute_reply":"2025-02-25T17:05:30.019906Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0                      id  \\\n0             0  eng_test_track_a_00001   \n1             1  eng_test_track_a_00002   \n2             2  eng_test_track_a_00003   \n3             3  eng_test_track_a_00004   \n4             4  eng_test_track_a_00005   \n..          ...                     ...   \n495         495  eng_test_track_a_00496   \n496         496  eng_test_track_a_00497   \n497         497  eng_test_track_a_00498   \n498         498  eng_test_track_a_00499   \n499         499  eng_test_track_a_00500   \n\n                                                  text  anger  fear  joy  \\\n0    / o \\ So today I went in for a new exam with D...      1     1    0   \n1    The image I have in my mind is this: a group o...      0     1    0   \n2    I slammed my fist against the door and yelled,...      1     1    0   \n3                         I could not unbend my knees.      0     1    0   \n4    I spent the night at the hotel, mostly hanging...      0     1    0   \n..                                                 ...    ...   ...  ...   \n495  The guy superficially looked like me (short br...      0     1    0   \n496  I wanted to open my eyes, to make the bad drea...      0     1    0   \n497  I got bored and quickly shifted to Windows XP,...      0     0    1   \n498  after drinking all night i couldnt manage a fa...      0     1    0   \n499  Legal counsel recommended I not try to take he...      1     1    0   \n\n     sadness  surprise                              generated_explanation  \\\n0          0         0  The speaker describes a stressful situation, l...   \n1          1         0  The speaker describes a metaphorical emotional...   \n2          0         0  The speaker's frustration or desperation promp...   \n3          0         0  The speaker describes a physical limitation, p...   \n4          1         0  The speaker describes a situation of discomfor...   \n..       ...       ...                                                ...   \n495        0         1  The speaker reflects on a superficial resembla...   \n496        1         0  The speaker describes a vivid and unpleasant d...   \n497        0         0  The speaker describes a moment of relief or es...   \n498        1         0  The speaker describes a moment of intense phys...   \n499        1         0  The speaker describes a situation of vulnerabi...   \n\n                                    predicted_emotions  \n0    {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 0...  \n1    {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...  \n2    {\"Anger\": 1, \"Fear\": 0, \"Joy\": 0, \"Sadness\": 0...  \n3    {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 0...  \n4    {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...  \n..                                                 ...  \n495  {\"Anger\": 0, \"Fear\": 0, \"Joy\": 0, \"Sadness\": 0...  \n496  {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...  \n497  {\"Anger\": 0, \"Fear\": 0, \"Joy\": 1, \"Sadness\": 0...  \n498  {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...  \n499  {\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...  \n\n[500 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>generated_explanation</th>\n      <th>predicted_emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>eng_test_track_a_00001</td>\n      <td>/ o \\ So today I went in for a new exam with D...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes a stressful situation, l...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>eng_test_track_a_00002</td>\n      <td>The image I have in my mind is this: a group o...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker describes a metaphorical emotional...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>eng_test_track_a_00003</td>\n      <td>I slammed my fist against the door and yelled,...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker's frustration or desperation promp...</td>\n      <td>{\"Anger\": 1, \"Fear\": 0, \"Joy\": 0, \"Sadness\": 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>eng_test_track_a_00004</td>\n      <td>I could not unbend my knees.</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes a physical limitation, p...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>eng_test_track_a_00005</td>\n      <td>I spent the night at the hotel, mostly hanging...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker describes a situation of discomfor...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>495</td>\n      <td>eng_test_track_a_00496</td>\n      <td>The guy superficially looked like me (short br...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>The speaker reflects on a superficial resembla...</td>\n      <td>{\"Anger\": 0, \"Fear\": 0, \"Joy\": 0, \"Sadness\": 0...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>496</td>\n      <td>eng_test_track_a_00497</td>\n      <td>I wanted to open my eyes, to make the bad drea...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker describes a vivid and unpleasant d...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>497</td>\n      <td>eng_test_track_a_00498</td>\n      <td>I got bored and quickly shifted to Windows XP,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>The speaker describes a moment of relief or es...</td>\n      <td>{\"Anger\": 0, \"Fear\": 0, \"Joy\": 1, \"Sadness\": 0...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>498</td>\n      <td>eng_test_track_a_00499</td>\n      <td>after drinking all night i couldnt manage a fa...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker describes a moment of intense phys...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>499</td>\n      <td>eng_test_track_a_00500</td>\n      <td>Legal counsel recommended I not try to take he...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>The speaker describes a situation of vulnerabi...</td>\n      <td>{\"Anger\": 0, \"Fear\": 1, \"Joy\": 0, \"Sadness\": 1...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":47}]}